name: Semgrep SCA Coverage Report

on:
  # Scan on-demand through GitHub Actions interface:
  workflow_dispatch: {}
  # Schedule the CI job (this method uses cron syntax):
  schedule:
    - cron: '20 17 * * *' # Sets Semgrep to scan every day at 17:20 UTC.
    
jobs:
  get-list-of-repos:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        pip install requests
        pip install pandas
        
    - name: Generate SCA report
      env:
        # Generate PAT with Read-Only access to all repos in your GH ORG
        PAT_READ_ONLY_CUSTOMER_REPO: ${{ secrets.PAT_READ_ONLY_CUSTOMER_REPO }}
        SEMGREP_APP_TOKEN:  ${{ secrets.SEMGREP_APP_TOKEN }}
        DEBUG_LEVEL: ${{ vars.COVERAGE_REPORT_DEBUG_LEVEL }}

      run: |
        import requests
        import os
        import pandas as pd
        import json
        import sys
        import time
        import logging

        ############################################
        # Function to get the Semgrep deployment ID
        ############################################
        def get_deployment_id(token):
            headers = {"Accept": "application/json", "Authorization": "Bearer " + token}
            r = requests.get('https://semgrep.dev/api/v1/deployments',headers=headers)
            if r.status_code != 200:
                sys.exit(f'Could not get deployment: {r.status_code} {r.text}')
            org_id = str(r.json()['deployments'][0].get('id'))
            logging.info("Accessing org: " + org_id)
            return org_id

        ############################################
        # Function to get the Semgrep deployment name
        ############################################
        def get_deployment_slug_name(token):
            headers = {"Accept": "application/json", "Authorization": "Bearer " + token}
            r = requests.get('https://semgrep.dev/api/v1/deployments',headers=headers)
            if r.status_code != 200:
                sys.exit(f'Could not get deployment: {r.status_code} {r.text}')
            slug = str(r.json()['deployments'][0].get('slug'))
            logging.info("Accessing org: " + slug)
            return slug
        ############################################   
        # Function to convert debug level from string to logging module constant
        ############################################
        def get_debug_level(level_str):
            return {
                'DEBUG': logging.DEBUG,
                'INFO': logging.INFO,
                'WARNING': logging.WARNING,
                'ERROR': logging.ERROR,
                'CRITICAL': logging.CRITICAL
            }.get(level_str.upper(), logging.INFO) # Default to INFO if not matched

        # Read DEBUG_LEVEL from environment and set logging level
        debug_level_str = os.getenv('DEBUG_LEVEL', 'INFO') # Default to INFO if not set
        print(f'Debug Level set to: {debug_level_str}')
        logging.basicConfig(level=get_debug_level(debug_level_str), format='%(asctime)s - %(levelname)s - %(message)s')

        ############################################
        # Function to check if a repo is empty or not
        ############################################
        def is_repo_empty(repo_name, pat):
            """
            Check if a GitHub repository is empty using the GitHub API.
            """
            url = f"https://api.github.com/repos/{repo_name}/branches"
            headers = {"Authorization": f"token {pat}"}
        
            try:
                response = requests.get(url, headers=headers)
                response.raise_for_status()  # Raise an error for bad responses
        
                # Check if the list of branches is empty
                if response.json():
                    logging.info(f"The repository '{repo_name}' is not empty.")
                    return "Not Empty"
                else:
                    logging.info(f"The repository '{repo_name}' is empty.")
                    return "Empty"
            except requests.exceptions.RequestException as e:
                logging.error(f"An error occurred while checking the repository: {e}")
                return False  # Assuming False in case of an error

        ############################################
        # Function to get all Semgrep projects
        ############################################
        def get_semgrep_all_repos():
            semgrep_token = os.environ['SEMGREP_APP_TOKEN']
            headers = {"Accept": "application/json", "Authorization": "Bearer " + semgrep_token}
            params =  {"page_size": 3000}
  
            slug_name = get_deployment_slug_name(semgrep_token)
            r = requests.get(f"https://semgrep.dev/api/v1/deployments/{slug_name}/projects?page=0", params=params, headers=headers)
            if r.status_code != 200:
              logging.error("Getting list of projects from Semgrep failed - please check Semgrep API token")
              sys.exit(f'Get failed: {r.text}')
  
            semgrep_repos = json.loads(r.text)
            return semgrep_repos

        ############################################
        # Function to Retry logic in case 504 error
        ############################################
        def make_request_with_retries(endpoint, headers, payload, retries=3):
            for attempt in range(retries):
                r = requests.post(f"{endpoint}", headers=headers, json=payload)
                if r.status_code == 504:
                    print(f"Request timed out (504), attempt {attempt + 1} of {retries}. Retrying in 5 seconds...")
                    time.sleep(5)  # Wait before retrying
                else:
                    return r  # Return the response if it's not a 504
            sys.exit("Request failed after 3 attempts due to 504 errors.")
    
        ############################################
        # Function to iterate through all the items given an endpoint
        ############################################
        def retrieve_paginated_data(endpoint, kind, headers):
            """
            Generalized function to retrieve multiple pages of data.
            Returns all data as a JSON string (not a Python dict!) in the same format 
            as the API would if it weren't paginated.
            """
            # Initialize values
            data_list = []
            hasMore = True
            cursor = 0
            
            while (hasMore == True):
                payload = {"pageSize": 100, "cursor": cursor}
                r = make_request_with_retries(endpoint, headers, payload)

                if r.status_code != 200:
                    sys.exit(f'Get failed: {r.text}')
                    
                data = r.json()
                hasMore = data['hasMore']
                print(f"Is there more items to check: ",{hasMore})

                if hasMore == True:
                    print(f"Waiting 5 seconds...cursor: ",{cursor})
                    cursor = data['cursor']
                    time.sleep(5)
                data_list.extend(data.get(kind))
            return json.dumps({ f"{kind}": data_list})
        
        
        ############################################
        # Function to get all Semgrep projects with dependencies
        ############################################
        def get_repo_with_dependencies(org_id, headers):
            projects = retrieve_paginated_data(f"https://semgrep.dev/api/v1/deployments/{org_id}/dependencies/repositories", "repositorySummaries", headers=headers)
            return projects

        ############################################
        # Function to get all Semgrep projects with dependencies
        ############################################
        def get_semgrep_dep_repos():
            semgrep_token = os.environ['SEMGREP_APP_TOKEN']
            org_id = get_deployment_id(semgrep_token)
            headers = {"Accept": "application/json", "Authorization": "Bearer " + semgrep_token}
            repos_with_deps = get_repo_with_dependencies(org_id, headers)
            return json.loads(repos_with_deps)
            
        ############################################
        # Function to merge two dataframes
        ############################################
        def merge_semgrep_df(semgrep_all_repos, semgrep_repos_dep_details):

            merged_results = []
            
            # Create a set of ids from the first dictionary for quick lookup
            repo_ids = {repo['id'] for repo in semgrep_repos_dep_details['repositorySummaries']}
        
            # Iterate over semgrep_repos_dep_details and semgrep_all_repos to find matching ids and merge them
            for repo in semgrep_repos_dep_details['repositorySummaries']:
                repo_id = repo['id']
                for project in semgrep_all_repos['projects']:
                    if project['id'] == repo_id:
                        merged_result = {**repo, **project}
                        merged_results.append(merged_result)
    
            # Add items from the second dictionary that do not have a match in the first dictionary
            for project in semgrep_all_repos['projects']:
                if project['id'] not in repo_ids:
                    merged_result = {**project, 'numDependencies': 0}
                    merged_results.append(merged_result)
                    
            return merged_results
        
        # GitHub repository in the format "org_name/repo_name"
        full_repo_name = os.environ['GITHUB_REPOSITORY']

        # Extract the organization name
        org_name = full_repo_name.split('/')[0]
        logging.info(f"Organization Name: {org_name}")
        pat = os.environ['PAT_READ_ONLY_CUSTOMER_REPO']
        headers = {'Authorization': f'token {pat}'}

        repos = []
        page = 1
        while True:
            url = f'https://api.github.com/orgs/{org_name}/repos?page={page}&per_page=100'
            response = requests.get(url, headers=headers)
            logging.debug(f"Requesting list of repos in Org: {org_name}, page: {page}")
            logging.debug(f"Response Code: {response.status_code}")
            page_repos = response.json()
            if not page_repos:
                break
            repos.extend(page_repos)
            page += 1
        logging.debug(f"Read list of repos from GitHub API successful- number of repos = {len(repos)} ")

        semgrep_all_repos = get_semgrep_all_repos()

        semgrep_repos_dep_details = get_semgrep_dep_repos()
        
        # Create a new list to store the merged results
        merged_results = merge_semgrep_df(semgrep_all_repos, semgrep_repos_dep_details)

        coverage_data = []
        
        for repo in repos:
            repo_name = repo['name']
            repo_full_name = repo['full_name']
            logging.debug(f"processing GitHub repo start - {repo_full_name}")
            created_at = repo['created_at']
            html_url = repo['html_url']
            repo_empty_state = is_repo_empty(repo_full_name, pat)

            latest_scan = None
            sca_coverage = 0
            num_dependencies = 0
            for sg_repo in merged_results:
                semgrep_repo_name = sg_repo['name']
                logging.debug(f"processing Semgrep repo start - {semgrep_repo_name}")
                if semgrep_repo_name == repo_full_name:
                    logging.debug("Repo with dependencies!")
                    latest_scan = sg_repo['latest_scan_at']
                    sca_coverage = 1
                    num_dependencies = sg_repo['numDependencies']
                    break
            
            if latest_scan is None:
                logging.info(f"{repo_name} not scanned by Semgrep yet")
            
            coverage_data.append([repo_full_name, sca_coverage, num_dependencies, latest_scan, created_at, html_url, repo_empty_state])
            logging.debug(f"processing repo end - {repo_full_name}: {repo_full_name} , {sca_coverage}, {num_dependencies}, {latest_scan}, {created_at}, {html_url}, {repo_empty_state}")

        
        coverage_df = pd.DataFrame(coverage_data, columns=['Repository', 'SCA Coverage', 'Num Dependencies', 'Latest Scan', 'Created At', 'URL', 'Is Repo Empty'])
        coverage_df.to_csv('coverage_sca.csv', index=False)
      
      shell: python
      
    - name: Upload coverage_sca.csv as Artifact
      uses: actions/upload-artifact@v4
      with:
        name: semgrep-coverage-sca-report.csv
        path: |
          daily_repos_not_in_github_repos.csv
          weekly_repos_not_in_github_repos.csv
          coverage_sca.csv
